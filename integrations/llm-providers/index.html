<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Graph-based orchestration framework for production multi-agent systems"><link href=https://lionagi.ai/integrations/llm-providers/ rel=canonical><link href=../ rel=prev><link href=../vector-stores/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.20"><title>LLM Providers - LionAGI</title><link rel=stylesheet href=../../assets/stylesheets/main.e53b48f4.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style><link rel=stylesheet href=../../assets/_mkdocstrings.css><link rel=stylesheet href=../../stylesheets/extra.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600&display=swap"><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config",""),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=black data-md-color-accent=amber> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#llm-provider-integration class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title=LionAGI class="md-header__button md-logo" aria-label=LionAGI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19.5 17c-.13 0-.26 0-.39.04l-1.61-3.25a2.5 2.5 0 0 0-1.75-4.29c-.13 0-.25 0-.39.04l-1.63-3.25c.48-.45.77-1.08.77-1.79a2.5 2.5 0 0 0-5 0c0 .71.29 1.34.76 1.79L8.64 9.54c-.14-.04-.26-.04-.39-.04a2.5 2.5 0 0 0-1.75 4.29l-1.61 3.25C4.76 17 4.63 17 4.5 17a2.5 2.5 0 0 0 0 5A2.5 2.5 0 0 0 7 19.5c0-.7-.29-1.34-.76-1.79l1.62-3.25c.14.04.26.04.39.04s.25 0 .39-.04l1.63 3.25c-.47.45-.77 1.09-.77 1.79a2.5 2.5 0 0 0 5 0A2.5 2.5 0 0 0 12 17c-.13 0-.26 0-.39.04L10 13.79c.46-.45.75-1.08.75-1.79s-.29-1.34-.75-1.79l1.61-3.25c.13.04.26.04.39.04s.26 0 .39-.04L14 10.21c-.45.45-.75 1.09-.75 1.79a2.5 2.5 0 0 0 2.5 2.5c.13 0 .25 0 .39-.04l1.63 3.25c-.47.45-.77 1.09-.77 1.79a2.5 2.5 0 0 0 5 0 2.5 2.5 0 0 0-2.5-2.5"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> LionAGI </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> LLM Providers </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=black data-md-color-accent=amber aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=amber aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/khive-ai/lionagi title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> khive-ai/lionagi </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../core-concepts/ class=md-tabs__link> Learn </a> </li> <li class=md-tabs__item> <a href=../../patterns/ class=md-tabs__link> Patterns </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../advanced/ class=md-tabs__link> Build </a> </li> <li class=md-tabs__item> <a href=../../for-ai-agents/ class=md-tabs__link> For AI Agents </a> </li> <li class=md-tabs__item> <a href=../../reference/api/ class=md-tabs__link> Reference </a> </li> <li class=md-tabs__item> <a href=../../contributing/ class=md-tabs__link> Community </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title=LionAGI class="md-nav__button md-logo" aria-label=LionAGI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19.5 17c-.13 0-.26 0-.39.04l-1.61-3.25a2.5 2.5 0 0 0-1.75-4.29c-.13 0-.25 0-.39.04l-1.63-3.25c.48-.45.77-1.08.77-1.79a2.5 2.5 0 0 0-5 0c0 .71.29 1.34.76 1.79L8.64 9.54c-.14-.04-.26-.04-.39-.04a2.5 2.5 0 0 0-1.75 4.29l-1.61 3.25C4.76 17 4.63 17 4.5 17a2.5 2.5 0 0 0 0 5A2.5 2.5 0 0 0 7 19.5c0-.7-.29-1.34-.76-1.79l1.62-3.25c.14.04.26.04.39.04s.25 0 .39-.04l1.63 3.25c-.47.45-.77 1.09-.77 1.79a2.5 2.5 0 0 0 5 0A2.5 2.5 0 0 0 12 17c-.13 0-.26 0-.39.04L10 13.79c.46-.45.75-1.08.75-1.79s-.29-1.34-.75-1.79l1.61-3.25c.13.04.26.04.39.04s.26 0 .39-.04L14 10.21c-.45.45-.75 1.09-.75 1.79a2.5 2.5 0 0 0 2.5 2.5c.13 0 .25 0 .39-.04l1.63 3.25c-.47.45-.77 1.09-.77 1.79a2.5 2.5 0 0 0 5 0 2.5 2.5 0 0 0-2.5-2.5"/></svg> </a> LionAGI </label> <div class=md-nav__source> <a href=https://github.com/khive-ai/lionagi title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> khive-ai/lionagi </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../core-concepts/ class=md-nav__link> <span class=md-ellipsis> Learn </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../patterns/ class=md-nav__link> <span class=md-ellipsis> Patterns </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex> <span class=md-ellipsis> Build </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Build </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_1> <div class="md-nav__link md-nav__container"> <a href=../../advanced/ class="md-nav__link "> <span class=md-ellipsis> Advanced </span> </a> <label class="md-nav__link " for=__nav_4_1 id=__nav_4_1_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_1_label aria-expanded=false> <label class=md-nav__title for=__nav_4_1> <span class="md-nav__icon md-icon"></span> Advanced </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../advanced/custom-operations/ class=md-nav__link> <span class=md-ellipsis> Custom Operations </span> </a> </li> <li class=md-nav__item> <a href=../../advanced/flow-composition/ class=md-nav__link> <span class=md-ellipsis> Flow Composition </span> </a> </li> <li class=md-nav__item> <a href=../../advanced/performance/ class=md-nav__link> <span class=md-ellipsis> Performance </span> </a> </li> <li class=md-nav__item> <a href=../../advanced/error-handling/ class=md-nav__link> <span class=md-ellipsis> Error Handling </span> </a> </li> <li class=md-nav__item> <a href=../../advanced/observability/ class=md-nav__link> <span class=md-ellipsis> Observability </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> Integrations </span> </a> <label class="md-nav__link " for=__nav_4_2 id=__nav_4_2_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=true> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> Integrations </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> LLM Providers </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> LLM Providers </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#how-provider-selection-works class=md-nav__link> <span class=md-ellipsis> How Provider Selection Works </span> </a> </li> <li class=md-nav__item> <a href=#quick-reference class=md-nav__link> <span class=md-ellipsis> Quick Reference </span> </a> </li> <li class=md-nav__item> <a href=#installation class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=#openai class=md-nav__link> <span class=md-ellipsis> OpenAI </span> </a> <nav class=md-nav aria-label=OpenAI> <ul class=md-nav__list> <li class=md-nav__item> <a href=#setup class=md-nav__link> <span class=md-ellipsis> Setup </span> </a> </li> <li class=md-nav__item> <a href=#basic-usage class=md-nav__link> <span class=md-ellipsis> Basic Usage </span> </a> </li> <li class=md-nav__item> <a href=#endpoints class=md-nav__link> <span class=md-ellipsis> Endpoints </span> </a> </li> <li class=md-nav__item> <a href=#structured-output class=md-nav__link> <span class=md-ellipsis> Structured Output </span> </a> </li> <li class=md-nav__item> <a href=#available-models class=md-nav__link> <span class=md-ellipsis> Available Models </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#anthropic class=md-nav__link> <span class=md-ellipsis> Anthropic </span> </a> <nav class=md-nav aria-label=Anthropic> <ul class=md-nav__list> <li class=md-nav__item> <a href=#setup_1 class=md-nav__link> <span class=md-ellipsis> Setup </span> </a> </li> <li class=md-nav__item> <a href=#basic-usage_1 class=md-nav__link> <span class=md-ellipsis> Basic Usage </span> </a> </li> <li class=md-nav__item> <a href=#prompt-caching class=md-nav__link> <span class=md-ellipsis> Prompt Caching </span> </a> </li> <li class=md-nav__item> <a href=#available-models_1 class=md-nav__link> <span class=md-ellipsis> Available Models </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#google-gemini-native-api class=md-nav__link> <span class=md-ellipsis> Google Gemini (Native API) </span> </a> <nav class=md-nav aria-label="Google Gemini (Native API)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#setup_2 class=md-nav__link> <span class=md-ellipsis> Setup </span> </a> </li> <li class=md-nav__item> <a href=#basic-usage_2 class=md-nav__link> <span class=md-ellipsis> Basic Usage </span> </a> </li> <li class=md-nav__item> <a href=#available-models_2 class=md-nav__link> <span class=md-ellipsis> Available Models </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#ollama-local-models class=md-nav__link> <span class=md-ellipsis> Ollama (Local Models) </span> </a> <nav class=md-nav aria-label="Ollama (Local Models)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#setup_3 class=md-nav__link> <span class=md-ellipsis> Setup </span> </a> </li> <li class=md-nav__item> <a href=#basic-usage_3 class=md-nav__link> <span class=md-ellipsis> Basic Usage </span> </a> </li> <li class=md-nav__item> <a href=#auto-pull class=md-nav__link> <span class=md-ellipsis> Auto-Pull </span> </a> </li> <li class=md-nav__item> <a href=#custom-base-url class=md-nav__link> <span class=md-ellipsis> Custom Base URL </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#perplexity class=md-nav__link> <span class=md-ellipsis> Perplexity </span> </a> <nav class=md-nav aria-label=Perplexity> <ul class=md-nav__list> <li class=md-nav__item> <a href=#setup_4 class=md-nav__link> <span class=md-ellipsis> Setup </span> </a> </li> <li class=md-nav__item> <a href=#basic-usage_4 class=md-nav__link> <span class=md-ellipsis> Basic Usage </span> </a> </li> <li class=md-nav__item> <a href=#available-models_3 class=md-nav__link> <span class=md-ellipsis> Available Models </span> </a> </li> <li class=md-nav__item> <a href=#provider-specific-parameters class=md-nav__link> <span class=md-ellipsis> Provider-Specific Parameters </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#groq class=md-nav__link> <span class=md-ellipsis> Groq </span> </a> <nav class=md-nav aria-label=Groq> <ul class=md-nav__list> <li class=md-nav__item> <a href=#setup_5 class=md-nav__link> <span class=md-ellipsis> Setup </span> </a> </li> <li class=md-nav__item> <a href=#basic-usage_5 class=md-nav__link> <span class=md-ellipsis> Basic Usage </span> </a> </li> <li class=md-nav__item> <a href=#available-models_4 class=md-nav__link> <span class=md-ellipsis> Available Models </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#openrouter class=md-nav__link> <span class=md-ellipsis> OpenRouter </span> </a> <nav class=md-nav aria-label=OpenRouter> <ul class=md-nav__list> <li class=md-nav__item> <a href=#setup_6 class=md-nav__link> <span class=md-ellipsis> Setup </span> </a> </li> <li class=md-nav__item> <a href=#basic-usage_6 class=md-nav__link> <span class=md-ellipsis> Basic Usage </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#nvidia-nim class=md-nav__link> <span class=md-ellipsis> NVIDIA NIM </span> </a> <nav class=md-nav aria-label="NVIDIA NIM"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#setup_7 class=md-nav__link> <span class=md-ellipsis> Setup </span> </a> </li> <li class=md-nav__item> <a href=#chat-endpoint class=md-nav__link> <span class=md-ellipsis> Chat Endpoint </span> </a> </li> <li class=md-nav__item> <a href=#embedding-endpoint class=md-nav__link> <span class=md-ellipsis> Embedding Endpoint </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#exa-search class=md-nav__link> <span class=md-ellipsis> Exa (Search) </span> </a> <nav class=md-nav aria-label="Exa (Search)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#setup_8 class=md-nav__link> <span class=md-ellipsis> Setup </span> </a> </li> <li class=md-nav__item> <a href=#basic-usage_7 class=md-nav__link> <span class=md-ellipsis> Basic Usage </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#cli-providers-coding-agents class=md-nav__link> <span class=md-ellipsis> CLI Providers (Coding Agents) </span> </a> <nav class=md-nav aria-label="CLI Providers (Coding Agents)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#how-cli-endpoints-work class=md-nav__link> <span class=md-ellipsis> How CLI Endpoints Work </span> </a> </li> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=#claude-code-cli class=md-nav__link> <span class=md-ellipsis> Claude Code CLI </span> </a> </li> <li class=md-nav__item> <a href=#gemini-cli class=md-nav__link> <span class=md-ellipsis> Gemini CLI </span> </a> </li> <li class=md-nav__item> <a href=#codex-cli class=md-nav__link> <span class=md-ellipsis> Codex CLI </span> </a> </li> <li class=md-nav__item> <a href=#context-and-session-management class=md-nav__link> <span class=md-ellipsis> Context and Session Management </span> </a> </li> <li class=md-nav__item> <a href=#event-handlers class=md-nav__link> <span class=md-ellipsis> Event Handlers </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#provider-auto-detection class=md-nav__link> <span class=md-ellipsis> Provider Auto-Detection </span> </a> </li> <li class=md-nav__item> <a href=#openai-compatible-custom-providers class=md-nav__link> <span class=md-ellipsis> OpenAI-Compatible Custom Providers </span> </a> </li> <li class=md-nav__item> <a href=#async-context-manager class=md-nav__link> <span class=md-ellipsis> Async Context Manager </span> </a> </li> <li class=md-nav__item> <a href=#copying-models class=md-nav__link> <span class=md-ellipsis> Copying Models </span> </a> </li> <li class=md-nav__item> <a href=#rate-limiting-and-concurrency class=md-nav__link> <span class=md-ellipsis> Rate Limiting and Concurrency </span> </a> </li> <li class=md-nav__item> <a href=#multiple-models-in-one-branch class=md-nav__link> <span class=md-ellipsis> Multiple Models in One Branch </span> </a> </li> <li class=md-nav__item> <a href=#environment-variable-reference class=md-nav__link> <span class=md-ellipsis> Environment Variable Reference </span> </a> </li> <li class=md-nav__item> <a href=#troubleshooting class=md-nav__link> <span class=md-ellipsis> Troubleshooting </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../vector-stores/ class=md-nav__link> <span class=md-ellipsis> Vector Stores </span> </a> </li> <li class=md-nav__item> <a href=../databases/ class=md-nav__link> <span class=md-ellipsis> Databases </span> </a> </li> <li class=md-nav__item> <a href=../tools/ class=md-nav__link> <span class=md-ellipsis> Tools </span> </a> </li> <li class=md-nav__item> <a href=../mcp-servers/ class=md-nav__link> <span class=md-ellipsis> MCP Servers </span> </a> </li> <li class=md-nav__item> <a href=../llamaindex-rag/ class=md-nav__link> <span class=md-ellipsis> LlamaIndex RAG </span> </a> </li> <li class=md-nav__item> <a href=../dspy-optimization/ class=md-nav__link> <span class=md-ellipsis> DSPy Optimization </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../for-ai-agents/ class=md-nav__link> <span class=md-ellipsis> For AI Agents </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../reference/api/ class=md-nav__link> <span class=md-ellipsis> Reference </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../contributing/ class=md-nav__link> <span class=md-ellipsis> Community </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/khive-ai/lionagi/edit/main/docs/integrations/llm-providers.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75z"/></svg> </a> <a href=https://github.com/khive-ai/lionagi/raw/main/docs/integrations/llm-providers.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5"/></svg> </a> <h1 id=llm-provider-integration>LLM Provider Integration<a class=headerlink href=#llm-provider-integration title="Permanent link">&para;</a></h1> <p>LionAGI supports 12 providers through a unified <code>iModel</code> interface. All providers work with the same <code>Branch</code> API -- swap the model and your application code stays the same.</p> <h2 id=how-provider-selection-works>How Provider Selection Works<a class=headerlink href=#how-provider-selection-works title="Permanent link">&para;</a></h2> <p>Every LLM call in LionAGI goes through <code>iModel</code>, which wraps an <code>Endpoint</code> for a specific provider. When you create an <code>iModel</code>, the <code>match_endpoint</code> function selects the right endpoint class based on the <code>provider</code> and <code>endpoint</code> strings you pass in. API keys are resolved automatically from environment variables (or <code>.env</code> / <code>.env.local</code> / <code>.secrets.env</code> files) via pydantic-settings.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=c1># Explicit provider + model</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=n>model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;openai&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-4.1-mini&quot;</span><span class=p>)</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=c1># Slash-syntax auto-detects provider from the model string</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=n>model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&quot;openai/gpt-4.1-mini&quot;</span><span class=p>)</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a><span class=c1># Branch uses the model for all LLM operations</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span><span class=n>chat_model</span><span class=o>=</span><span class=n>model</span><span class=p>)</span>
</span></code></pre></div> <h2 id=quick-reference>Quick Reference<a class=headerlink href=#quick-reference title="Permanent link">&para;</a></h2> <table> <thead> <tr> <th>Provider</th> <th><code>provider=</code></th> <th>Env Var for API Key</th> <th>Endpoint(s)</th> <th>Default Model</th> </tr> </thead> <tbody> <tr> <td>OpenAI</td> <td><code>"openai"</code></td> <td><code>OPENAI_API_KEY</code></td> <td><code>"chat"</code>, <code>"response"</code></td> <td><code>gpt-4.1-mini</code></td> </tr> <tr> <td>Anthropic</td> <td><code>"anthropic"</code></td> <td><code>ANTHROPIC_API_KEY</code></td> <td><code>"chat"</code> / <code>"messages"</code></td> <td>--</td> </tr> <tr> <td>Google Gemini</td> <td><code>"gemini"</code></td> <td><code>GEMINI_API_KEY</code></td> <td><code>"chat"</code></td> <td><code>gemini-2.5-flash</code></td> </tr> <tr> <td>Ollama</td> <td><code>"ollama"</code></td> <td><em>(none required)</em></td> <td><code>"chat"</code></td> <td>--</td> </tr> <tr> <td>Perplexity</td> <td><code>"perplexity"</code></td> <td><code>PERPLEXITY_API_KEY</code></td> <td><code>"chat"</code></td> <td><code>sonar</code></td> </tr> <tr> <td>Groq</td> <td><code>"groq"</code></td> <td><code>GROQ_API_KEY</code></td> <td><code>"chat"</code></td> <td><code>llama-3.3-70b-versatile</code></td> </tr> <tr> <td>OpenRouter</td> <td><code>"openrouter"</code></td> <td><code>OPENROUTER_API_KEY</code></td> <td><code>"chat"</code></td> <td><code>google/gemini-2.5-flash</code></td> </tr> <tr> <td>NVIDIA NIM</td> <td><code>"nvidia_nim"</code></td> <td><code>NVIDIA_NIM_API_KEY</code></td> <td><code>"chat"</code>, <code>"embed"</code></td> <td><code>meta/llama3-8b-instruct</code></td> </tr> <tr> <td>Exa</td> <td><code>"exa"</code></td> <td><code>EXA_API_KEY</code></td> <td><code>"search"</code></td> <td>--</td> </tr> <tr> <td>Claude Code CLI</td> <td><code>"claude_code"</code></td> <td><em>(uses local CLI)</em></td> <td><code>"query_cli"</code></td> <td><code>sonnet</code></td> </tr> <tr> <td>Gemini CLI</td> <td><code>"gemini_code"</code></td> <td><em>(uses local CLI)</em></td> <td><code>"query_cli"</code></td> <td><code>gemini-2.5-pro</code></td> </tr> <tr> <td>Codex CLI</td> <td><code>"codex"</code></td> <td><em>(uses local CLI)</em></td> <td><code>"query_cli"</code></td> <td><code>gpt-5.3-codex</code></td> </tr> </tbody> </table> <h2 id=installation>Installation<a class=headerlink href=#installation title="Permanent link">&para;</a></h2> <div class="language-bash highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># Core package (includes OpenAI, Anthropic, Gemini, Groq, OpenRouter,</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=c1># Perplexity, NVIDIA NIM, Exa support)</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>uv<span class=w> </span>pip<span class=w> </span>install<span class=w> </span>lionagi
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=c1># For Ollama local models</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a>uv<span class=w> </span>pip<span class=w> </span>install<span class=w> </span><span class=s2>&quot;lionagi[ollama]&quot;</span>
</span></code></pre></div> <hr> <h2 id=openai>OpenAI<a class=headerlink href=#openai title="Permanent link">&para;</a></h2> <h3 id=setup>Setup<a class=headerlink href=#setup title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=nb>export</span><span class=w> </span><span class=nv>OPENAI_API_KEY</span><span class=o>=</span><span class=s2>&quot;sk-...&quot;</span>
</span></code></pre></div> <h3 id=basic-usage>Basic Usage<a class=headerlink href=#basic-usage title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>    <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>        <span class=n>chat_model</span><span class=o>=</span><span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;openai&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-4.1-mini&quot;</span><span class=p>)</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a>    <span class=p>)</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>    <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a>        <span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;Explain the difference between async and sync programming.&quot;</span>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a>    <span class=p>)</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-3-12><a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a>
</span><span id=__span-3-13><a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <p>If <code>OPENAI_API_KEY</code> is set and you do not pass a <code>chat_model</code>, Branch defaults to <code>provider="openai"</code>, <code>model="gpt-4.1-mini"</code> automatically (configurable via the <code>LIONAGI_CHAT_PROVIDER</code> and <code>LIONAGI_CHAT_MODEL</code> environment variables).</p> <h3 id=endpoints>Endpoints<a class=headerlink href=#endpoints title="Permanent link">&para;</a></h3> <p>OpenAI has two endpoint types:</p> <ul> <li><strong>Chat Completions</strong> (<code>endpoint="chat"</code>, the default) -- standard <code>chat/completions</code> API.</li> <li><strong>Responses</strong> (<code>endpoint="response"</code>) -- the newer <code>responses</code> API.</li> </ul> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=c1># Responses endpoint</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=n>model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;openai&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-4.1-mini&quot;</span><span class=p>,</span> <span class=n>endpoint</span><span class=o>=</span><span class=s2>&quot;response&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=structured-output>Structured Output<a class=headerlink href=#structured-output title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=kn>from</span><span class=w> </span><span class=nn>pydantic</span><span class=w> </span><span class=kn>import</span> <span class=n>BaseModel</span><span class=p>,</span> <span class=n>Field</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=k>class</span><span class=w> </span><span class=nc>SentimentResult</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>    <span class=n>sentiment</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=n>description</span><span class=o>=</span><span class=s2>&quot;positive, negative, or neutral&quot;</span><span class=p>)</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a>    <span class=n>confidence</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=n>description</span><span class=o>=</span><span class=s2>&quot;Confidence score 0-1&quot;</span><span class=p>)</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a>    <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a>        <span class=n>chat_model</span><span class=o>=</span><span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;openai&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-4.1-mini&quot;</span><span class=p>)</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a>    <span class=p>)</span>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a>    <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>operate</span><span class=p>(</span>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a>        <span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;Analyze the sentiment of this review.&quot;</span><span class=p>,</span>
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a>        <span class=n>context</span><span class=o>=</span><span class=s2>&quot;The product exceeded all my expectations!&quot;</span><span class=p>,</span>
</span><span id=__span-5-16><a id=__codelineno-5-16 name=__codelineno-5-16 href=#__codelineno-5-16></a>        <span class=n>operative_model</span><span class=o>=</span><span class=n>SentimentResult</span><span class=p>,</span>
</span><span id=__span-5-17><a id=__codelineno-5-17 name=__codelineno-5-17 href=#__codelineno-5-17></a>    <span class=p>)</span>
</span><span id=__span-5-18><a id=__codelineno-5-18 name=__codelineno-5-18 href=#__codelineno-5-18></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>  <span class=c1># Operative with .output containing a SentimentResult</span>
</span><span id=__span-5-19><a id=__codelineno-5-19 name=__codelineno-5-19 href=#__codelineno-5-19></a>
</span><span id=__span-5-20><a id=__codelineno-5-20 name=__codelineno-5-20 href=#__codelineno-5-20></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <h3 id=available-models>Available Models<a class=headerlink href=#available-models title="Permanent link">&para;</a></h3> <p>Any model available through the OpenAI API works. Common choices:</p> <ul> <li><code>gpt-4.1-mini</code> (default, cost-effective)</li> <li><code>gpt-4.1</code></li> <li><code>gpt-4o</code></li> <li><code>gpt-4o-mini</code></li> <li><code>o3-mini</code></li> </ul> <hr> <h2 id=anthropic>Anthropic<a class=headerlink href=#anthropic title="Permanent link">&para;</a></h2> <h3 id=setup_1>Setup<a class=headerlink href=#setup_1 title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=nb>export</span><span class=w> </span><span class=nv>ANTHROPIC_API_KEY</span><span class=o>=</span><span class=s2>&quot;sk-ant-...&quot;</span>
</span></code></pre></div> <h3 id=basic-usage_1>Basic Usage<a class=headerlink href=#basic-usage_1 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>    <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>        <span class=n>chat_model</span><span class=o>=</span><span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;anthropic&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;claude-sonnet-4-20250514&quot;</span><span class=p>)</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>    <span class=p>)</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a>    <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>        <span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;Analyze this code for potential issues.&quot;</span><span class=p>,</span>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a>        <span class=n>context</span><span class=o>=</span><span class=s2>&quot;def divide(a, b): return a / b&quot;</span><span class=p>,</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a>    <span class=p>)</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <p>The endpoint string can be <code>"chat"</code> or <code>"messages"</code> -- both resolve to the Anthropic Messages API. System messages in the conversation are automatically extracted and passed as the Anthropic <code>system</code> parameter.</p> <h3 id=prompt-caching>Prompt Caching<a class=headerlink href=#prompt-caching title="Permanent link">&para;</a></h3> <p>Anthropic supports prompt caching via <code>cache_control</code>. Pass it when invoking:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a>    <span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;Summarize this long document.&quot;</span><span class=p>,</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a>    <span class=n>context</span><span class=o>=</span><span class=n>long_document</span><span class=p>,</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>    <span class=n>cache_control</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a><span class=p>)</span>
</span></code></pre></div> <h3 id=available-models_1>Available Models<a class=headerlink href=#available-models_1 title="Permanent link">&para;</a></h3> <ul> <li><code>claude-sonnet-4-20250514</code></li> <li><code>claude-opus-4-20250514</code></li> <li><code>claude-3-5-sonnet-20241022</code></li> <li><code>claude-3-5-haiku-20241022</code></li> </ul> <hr> <h2 id=google-gemini-native-api>Google Gemini (Native API)<a class=headerlink href=#google-gemini-native-api title="Permanent link">&para;</a></h2> <h3 id=setup_2>Setup<a class=headerlink href=#setup_2 title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=nb>export</span><span class=w> </span><span class=nv>GEMINI_API_KEY</span><span class=o>=</span><span class=s2>&quot;...&quot;</span>
</span></code></pre></div> <h3 id=basic-usage_2>Basic Usage<a class=headerlink href=#basic-usage_2 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>    <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>        <span class=n>chat_model</span><span class=o>=</span><span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;gemini&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gemini-2.5-flash&quot;</span><span class=p>)</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>    <span class=p>)</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>    <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a>        <span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;Compare Python and Rust for systems programming.&quot;</span>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a>    <span class=p>)</span>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-10-12><a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>
</span><span id=__span-10-13><a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <p>The Gemini provider uses Google's OpenAI-compatible endpoint at <code>generativelanguage.googleapis.com/v1beta/openai</code>, so it accepts standard chat-completion parameters.</p> <h3 id=available-models_2>Available Models<a class=headerlink href=#available-models_2 title="Permanent link">&para;</a></h3> <ul> <li><code>gemini-2.5-flash</code> (default)</li> <li><code>gemini-2.5-pro</code></li> <li><code>gemini-2.0-flash</code></li> </ul> <hr> <h2 id=ollama-local-models>Ollama (Local Models)<a class=headerlink href=#ollama-local-models title="Permanent link">&para;</a></h2> <h3 id=setup_3>Setup<a class=headerlink href=#setup_3 title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=c1># 1. Install Ollama (https://ollama.com)</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a>curl<span class=w> </span>-fsSL<span class=w> </span>https://ollama.ai/install.sh<span class=w> </span><span class=p>|</span><span class=w> </span>sh
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a><span class=c1># 2. Install the lionagi Ollama extra</span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a>uv<span class=w> </span>pip<span class=w> </span>install<span class=w> </span><span class=s2>&quot;lionagi[ollama]&quot;</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a><span class=c1># 3. Pull a model</span>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a>ollama<span class=w> </span>pull<span class=w> </span>llama3.2:3b
</span></code></pre></div> <p>No API key is needed. The endpoint defaults to <code>http://localhost:11434/v1</code>.</p> <h3 id=basic-usage_3>Basic Usage<a class=headerlink href=#basic-usage_3 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>    <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a>        <span class=n>chat_model</span><span class=o>=</span><span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;ollama&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;llama3.2:3b&quot;</span><span class=p>)</span>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a>    <span class=p>)</span>
</span><span id=__span-12-8><a id=__codelineno-12-8 name=__codelineno-12-8 href=#__codelineno-12-8></a>    <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span>
</span><span id=__span-12-9><a id=__codelineno-12-9 name=__codelineno-12-9 href=#__codelineno-12-9></a>        <span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;Explain how transformers work in machine learning.&quot;</span>
</span><span id=__span-12-10><a id=__codelineno-12-10 name=__codelineno-12-10 href=#__codelineno-12-10></a>    <span class=p>)</span>
</span><span id=__span-12-11><a id=__codelineno-12-11 name=__codelineno-12-11 href=#__codelineno-12-11></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-12-12><a id=__codelineno-12-12 name=__codelineno-12-12 href=#__codelineno-12-12></a>
</span><span id=__span-12-13><a id=__codelineno-12-13 name=__codelineno-12-13 href=#__codelineno-12-13></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <h3 id=auto-pull>Auto-Pull<a class=headerlink href=#auto-pull title="Permanent link">&para;</a></h3> <p>If the requested model is not available locally, LionAGI will pull it from the Ollama registry automatically before the first call (with a progress bar via <code>tqdm</code>).</p> <h3 id=custom-base-url>Custom Base URL<a class=headerlink href=#custom-base-url title="Permanent link">&para;</a></h3> <p>If Ollama runs on a different host or port:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=n>model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a>    <span class=n>provider</span><span class=o>=</span><span class=s2>&quot;ollama&quot;</span><span class=p>,</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>    <span class=n>model</span><span class=o>=</span><span class=s2>&quot;llama3.2:3b&quot;</span><span class=p>,</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a>    <span class=n>base_url</span><span class=o>=</span><span class=s2>&quot;http://my-server:11434/v1&quot;</span><span class=p>,</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=perplexity>Perplexity<a class=headerlink href=#perplexity title="Permanent link">&para;</a></h2> <p>Perplexity provides real-time web search and Q&amp;A through their Sonar API.</p> <h3 id=setup_4>Setup<a class=headerlink href=#setup_4 title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=nb>export</span><span class=w> </span><span class=nv>PERPLEXITY_API_KEY</span><span class=o>=</span><span class=s2>&quot;pplx-...&quot;</span>
</span></code></pre></div> <h3 id=basic-usage_4>Basic Usage<a class=headerlink href=#basic-usage_4 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a>    <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span>
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a>        <span class=n>chat_model</span><span class=o>=</span><span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;perplexity&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;sonar&quot;</span><span class=p>)</span>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a>    <span class=p>)</span>
</span><span id=__span-15-8><a id=__codelineno-15-8 name=__codelineno-15-8 href=#__codelineno-15-8></a>    <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span>
</span><span id=__span-15-9><a id=__codelineno-15-9 name=__codelineno-15-9 href=#__codelineno-15-9></a>        <span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;What are the latest developments in quantum computing?&quot;</span>
</span><span id=__span-15-10><a id=__codelineno-15-10 name=__codelineno-15-10 href=#__codelineno-15-10></a>    <span class=p>)</span>
</span><span id=__span-15-11><a id=__codelineno-15-11 name=__codelineno-15-11 href=#__codelineno-15-11></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-15-12><a id=__codelineno-15-12 name=__codelineno-15-12 href=#__codelineno-15-12></a>
</span><span id=__span-15-13><a id=__codelineno-15-13 name=__codelineno-15-13 href=#__codelineno-15-13></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <h3 id=available-models_3>Available Models<a class=headerlink href=#available-models_3 title="Permanent link">&para;</a></h3> <ul> <li><code>sonar</code> (default)</li> <li><code>sonar-pro</code></li> <li><code>sonar-reasoning</code></li> <li><code>sonar-reasoning-pro</code></li> <li><code>sonar-deep-research</code></li> </ul> <h3 id=provider-specific-parameters>Provider-Specific Parameters<a class=headerlink href=#provider-specific-parameters title="Permanent link">&para;</a></h3> <p>Perplexity supports additional parameters that can be passed as kwargs:</p> <ul> <li><code>search_mode</code> -- <code>"default"</code> or <code>"academic"</code> (restricts to scholarly sources)</li> <li><code>search_domain_filter</code> -- list of domains to include/exclude (prefix with <code>"-"</code>)</li> <li><code>search_recency_filter</code> -- <code>"month"</code>, <code>"week"</code>, <code>"day"</code>, or <code>"hour"</code></li> <li><code>return_related_questions</code> -- <code>True</code>/<code>False</code></li> </ul> <hr> <h2 id=groq>Groq<a class=headerlink href=#groq title="Permanent link">&para;</a></h2> <h3 id=setup_5>Setup<a class=headerlink href=#setup_5 title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=nb>export</span><span class=w> </span><span class=nv>GROQ_API_KEY</span><span class=o>=</span><span class=s2>&quot;gsk_...&quot;</span>
</span></code></pre></div> <h3 id=basic-usage_5>Basic Usage<a class=headerlink href=#basic-usage_5 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a>    <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a>        <span class=n>chat_model</span><span class=o>=</span><span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;groq&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;llama-3.3-70b-versatile&quot;</span><span class=p>)</span>
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7 href=#__codelineno-17-7></a>    <span class=p>)</span>
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8 href=#__codelineno-17-8></a>    <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span>
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9 href=#__codelineno-17-9></a>        <span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;Fast inference test -- explain recursion in one paragraph.&quot;</span>
</span><span id=__span-17-10><a id=__codelineno-17-10 name=__codelineno-17-10 href=#__codelineno-17-10></a>    <span class=p>)</span>
</span><span id=__span-17-11><a id=__codelineno-17-11 name=__codelineno-17-11 href=#__codelineno-17-11></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-17-12><a id=__codelineno-17-12 name=__codelineno-17-12 href=#__codelineno-17-12></a>
</span><span id=__span-17-13><a id=__codelineno-17-13 name=__codelineno-17-13 href=#__codelineno-17-13></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <p>Groq uses an OpenAI-compatible API, so standard chat-completion parameters (<code>temperature</code>, <code>max_tokens</code>, <code>top_p</code>, etc.) are supported.</p> <h3 id=available-models_4>Available Models<a class=headerlink href=#available-models_4 title="Permanent link">&para;</a></h3> <ul> <li><code>llama-3.3-70b-versatile</code> (default)</li> <li><code>llama-3.1-8b-instant</code></li> <li><code>mixtral-8x7b-32768</code></li> </ul> <hr> <h2 id=openrouter>OpenRouter<a class=headerlink href=#openrouter title="Permanent link">&para;</a></h2> <p>OpenRouter provides access to many models through a single API.</p> <h3 id=setup_6>Setup<a class=headerlink href=#setup_6 title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a><span class=nb>export</span><span class=w> </span><span class=nv>OPENROUTER_API_KEY</span><span class=o>=</span><span class=s2>&quot;sk-or-...&quot;</span>
</span></code></pre></div> <h3 id=basic-usage_6>Basic Usage<a class=headerlink href=#basic-usage_6 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-19-3><a id=__codelineno-19-3 name=__codelineno-19-3 href=#__codelineno-19-3></a>
</span><span id=__span-19-4><a id=__codelineno-19-4 name=__codelineno-19-4 href=#__codelineno-19-4></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-19-5><a id=__codelineno-19-5 name=__codelineno-19-5 href=#__codelineno-19-5></a>    <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span>
</span><span id=__span-19-6><a id=__codelineno-19-6 name=__codelineno-19-6 href=#__codelineno-19-6></a>        <span class=n>chat_model</span><span class=o>=</span><span class=n>iModel</span><span class=p>(</span>
</span><span id=__span-19-7><a id=__codelineno-19-7 name=__codelineno-19-7 href=#__codelineno-19-7></a>            <span class=n>provider</span><span class=o>=</span><span class=s2>&quot;openrouter&quot;</span><span class=p>,</span>
</span><span id=__span-19-8><a id=__codelineno-19-8 name=__codelineno-19-8 href=#__codelineno-19-8></a>            <span class=n>model</span><span class=o>=</span><span class=s2>&quot;google/gemini-2.5-flash&quot;</span><span class=p>,</span>
</span><span id=__span-19-9><a id=__codelineno-19-9 name=__codelineno-19-9 href=#__codelineno-19-9></a>        <span class=p>)</span>
</span><span id=__span-19-10><a id=__codelineno-19-10 name=__codelineno-19-10 href=#__codelineno-19-10></a>    <span class=p>)</span>
</span><span id=__span-19-11><a id=__codelineno-19-11 name=__codelineno-19-11 href=#__codelineno-19-11></a>    <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span><span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;Hello from OpenRouter!&quot;</span><span class=p>)</span>
</span><span id=__span-19-12><a id=__codelineno-19-12 name=__codelineno-19-12 href=#__codelineno-19-12></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-19-13><a id=__codelineno-19-13 name=__codelineno-19-13 href=#__codelineno-19-13></a>
</span><span id=__span-19-14><a id=__codelineno-19-14 name=__codelineno-19-14 href=#__codelineno-19-14></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <p>OpenRouter is OpenAI-compatible. Use any model ID from the <a href=https://openrouter.ai/models>OpenRouter model list</a>.</p> <hr> <h2 id=nvidia-nim>NVIDIA NIM<a class=headerlink href=#nvidia-nim title="Permanent link">&para;</a></h2> <h3 id=setup_7>Setup<a class=headerlink href=#setup_7 title="Permanent link">&para;</a></h3> <p>Get an API key from <a href=https://build.nvidia.com/ >build.nvidia.com</a>.</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a><span class=nb>export</span><span class=w> </span><span class=nv>NVIDIA_NIM_API_KEY</span><span class=o>=</span><span class=s2>&quot;nvapi-...&quot;</span>
</span></code></pre></div> <h3 id=chat-endpoint>Chat Endpoint<a class=headerlink href=#chat-endpoint title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-21-3><a id=__codelineno-21-3 name=__codelineno-21-3 href=#__codelineno-21-3></a>
</span><span id=__span-21-4><a id=__codelineno-21-4 name=__codelineno-21-4 href=#__codelineno-21-4></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-21-5><a id=__codelineno-21-5 name=__codelineno-21-5 href=#__codelineno-21-5></a>    <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span>
</span><span id=__span-21-6><a id=__codelineno-21-6 name=__codelineno-21-6 href=#__codelineno-21-6></a>        <span class=n>chat_model</span><span class=o>=</span><span class=n>iModel</span><span class=p>(</span>
</span><span id=__span-21-7><a id=__codelineno-21-7 name=__codelineno-21-7 href=#__codelineno-21-7></a>            <span class=n>provider</span><span class=o>=</span><span class=s2>&quot;nvidia_nim&quot;</span><span class=p>,</span>
</span><span id=__span-21-8><a id=__codelineno-21-8 name=__codelineno-21-8 href=#__codelineno-21-8></a>            <span class=n>model</span><span class=o>=</span><span class=s2>&quot;meta/llama3-8b-instruct&quot;</span><span class=p>,</span>
</span><span id=__span-21-9><a id=__codelineno-21-9 name=__codelineno-21-9 href=#__codelineno-21-9></a>        <span class=p>)</span>
</span><span id=__span-21-10><a id=__codelineno-21-10 name=__codelineno-21-10 href=#__codelineno-21-10></a>    <span class=p>)</span>
</span><span id=__span-21-11><a id=__codelineno-21-11 name=__codelineno-21-11 href=#__codelineno-21-11></a>    <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span><span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;Explain GPU parallelism.&quot;</span><span class=p>)</span>
</span><span id=__span-21-12><a id=__codelineno-21-12 name=__codelineno-21-12 href=#__codelineno-21-12></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-21-13><a id=__codelineno-21-13 name=__codelineno-21-13 href=#__codelineno-21-13></a>
</span><span id=__span-21-14><a id=__codelineno-21-14 name=__codelineno-21-14 href=#__codelineno-21-14></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <h3 id=embedding-endpoint>Embedding Endpoint<a class=headerlink href=#embedding-endpoint title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a><span class=n>embed_model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2 href=#__codelineno-22-2></a>    <span class=n>provider</span><span class=o>=</span><span class=s2>&quot;nvidia_nim&quot;</span><span class=p>,</span>
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3 href=#__codelineno-22-3></a>    <span class=n>endpoint</span><span class=o>=</span><span class=s2>&quot;embed&quot;</span><span class=p>,</span>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4 href=#__codelineno-22-4></a>    <span class=n>model</span><span class=o>=</span><span class=s2>&quot;nvidia/nv-embed-v1&quot;</span><span class=p>,</span>
</span><span id=__span-22-5><a id=__codelineno-22-5 name=__codelineno-22-5 href=#__codelineno-22-5></a><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=exa-search>Exa (Search)<a class=headerlink href=#exa-search title="Permanent link">&para;</a></h2> <p>Exa is a search provider, not a chat provider. It uses <code>endpoint="search"</code>.</p> <h3 id=setup_8>Setup<a class=headerlink href=#setup_8 title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a><span class=nb>export</span><span class=w> </span><span class=nv>EXA_API_KEY</span><span class=o>=</span><span class=s2>&quot;...&quot;</span>
</span></code></pre></div> <h3 id=basic-usage_7>Basic Usage<a class=headerlink href=#basic-usage_7 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1 href=#__codelineno-24-1></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>iModel</span>
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2 href=#__codelineno-24-2></a>
</span><span id=__span-24-3><a id=__codelineno-24-3 name=__codelineno-24-3 href=#__codelineno-24-3></a><span class=n>search_model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;exa&quot;</span><span class=p>,</span> <span class=n>endpoint</span><span class=o>=</span><span class=s2>&quot;search&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>Exa supports search-specific parameters including <code>query</code>, <code>category</code>, <code>type</code> (<code>"keyword"</code>, <code>"neural"</code>, <code>"auto"</code>), <code>num_results</code>, <code>include_domains</code>, <code>exclude_domains</code>, date filters, and content retrieval options.</p> <hr> <h2 id=cli-providers-coding-agents>CLI Providers (Coding Agents)<a class=headerlink href=#cli-providers-coding-agents title="Permanent link">&para;</a></h2> <p>LionAGI integrates three CLI-based coding agents as first-class iModel providers. These wrap local CLI binaries (subprocess, not HTTP) and enable <strong>agent-to-agent orchestration</strong> -- your outer agent uses lionagi to spawn and coordinate inner coding agents.</p> <h3 id=how-cli-endpoints-work>How CLI Endpoints Work<a class=headerlink href=#how-cli-endpoints-work title="Permanent link">&para;</a></h3> <p>CLI providers inherit from <code>CLIEndpoint</code>, a subclass of <code>Endpoint</code> that replaces HTTP transport with subprocess execution:</p> <ul> <li><strong>Subprocess execution</strong> -- each call spawns the CLI binary and streams NDJSON from stdout, decoded incrementally (handles multibyte UTF-8 splits).</li> <li><strong>Session persistence</strong> -- the endpoint stores a <code>session_id</code> from the first response and automatically passes <code>--resume</code> on subsequent calls.</li> <li><strong>Conservative concurrency</strong> -- <code>DEFAULT_CONCURRENCY_LIMIT = 3</code>, <code>DEFAULT_QUEUE_CAPACITY = 10</code> (vs 100 for HTTP).</li> <li><strong>No API key needed</strong> -- authentication is handled by the installed CLI tool.</li> <li><strong>Event handlers</strong> -- optional callbacks (<code>on_text</code>, <code>on_tool_use</code>, <code>on_tool_result</code>, <code>on_final</code>) fire as the subprocess streams output.</li> </ul> <div class="language-python highlight"><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1 href=#__codelineno-25-1></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>iModel</span>
</span><span id=__span-25-2><a id=__codelineno-25-2 name=__codelineno-25-2 href=#__codelineno-25-2></a>
</span><span id=__span-25-3><a id=__codelineno-25-3 name=__codelineno-25-3 href=#__codelineno-25-3></a><span class=n>model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;claude_code&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;sonnet&quot;</span><span class=p>)</span>
</span><span id=__span-25-4><a id=__codelineno-25-4 name=__codelineno-25-4 href=#__codelineno-25-4></a>
</span><span id=__span-25-5><a id=__codelineno-25-5 name=__codelineno-25-5 href=#__codelineno-25-5></a><span class=c1># Check if a model uses a CLI endpoint</span>
</span><span id=__span-25-6><a id=__codelineno-25-6 name=__codelineno-25-6 href=#__codelineno-25-6></a><span class=n>model</span><span class=o>.</span><span class=n>is_cli</span>  <span class=c1># True</span>
</span></code></pre></div> <h3 id=prerequisites>Prerequisites<a class=headerlink href=#prerequisites title="Permanent link">&para;</a></h3> <p>Each CLI provider requires its binary installed and on <code>PATH</code>:</p> <table> <thead> <tr> <th>Provider</th> <th>Binary</th> <th>Install Command</th> </tr> </thead> <tbody> <tr> <td>Claude Code</td> <td><code>claude</code></td> <td><code>npm i -g @anthropic-ai/claude-code</code></td> </tr> <tr> <td>Gemini CLI</td> <td><code>gemini</code></td> <td><code>npm i -g @anthropic-ai/gemini-cli</code></td> </tr> <tr> <td>Codex</td> <td><code>codex</code></td> <td><code>npm i -g codex</code></td> </tr> </tbody> </table> <p>LionAGI detects availability at import time via <code>shutil.which()</code>.</p> <h3 id=claude-code-cli>Claude Code CLI<a class=headerlink href=#claude-code-cli title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-26-1><a id=__codelineno-26-1 name=__codelineno-26-1 href=#__codelineno-26-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-26-2><a id=__codelineno-26-2 name=__codelineno-26-2 href=#__codelineno-26-2></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-26-3><a id=__codelineno-26-3 name=__codelineno-26-3 href=#__codelineno-26-3></a>
</span><span id=__span-26-4><a id=__codelineno-26-4 name=__codelineno-26-4 href=#__codelineno-26-4></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-26-5><a id=__codelineno-26-5 name=__codelineno-26-5 href=#__codelineno-26-5></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span>
</span><span id=__span-26-6><a id=__codelineno-26-6 name=__codelineno-26-6 href=#__codelineno-26-6></a>        <span class=n>provider</span><span class=o>=</span><span class=s2>&quot;claude_code&quot;</span><span class=p>,</span>
</span><span id=__span-26-7><a id=__codelineno-26-7 name=__codelineno-26-7 href=#__codelineno-26-7></a>        <span class=n>model</span><span class=o>=</span><span class=s2>&quot;sonnet&quot;</span><span class=p>,</span>                          <span class=c1># &quot;sonnet&quot; or &quot;opus&quot;</span>
</span><span id=__span-26-8><a id=__codelineno-26-8 name=__codelineno-26-8 href=#__codelineno-26-8></a>        <span class=n>system_prompt</span><span class=o>=</span><span class=s2>&quot;You are a code reviewer.&quot;</span><span class=p>,</span> <span class=c1># system instructions</span>
</span><span id=__span-26-9><a id=__codelineno-26-9 name=__codelineno-26-9 href=#__codelineno-26-9></a>        <span class=n>permission_mode</span><span class=o>=</span><span class=s2>&quot;bypassPermissions&quot;</span><span class=p>,</span>      <span class=c1># skip approval prompts</span>
</span><span id=__span-26-10><a id=__codelineno-26-10 name=__codelineno-26-10 href=#__codelineno-26-10></a>        <span class=n>allowed_tools</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;Read&quot;</span><span class=p>,</span> <span class=s2>&quot;Grep&quot;</span><span class=p>,</span> <span class=s2>&quot;Glob&quot;</span><span class=p>,</span> <span class=s2>&quot;Bash&quot;</span><span class=p>],</span>
</span><span id=__span-26-11><a id=__codelineno-26-11 name=__codelineno-26-11 href=#__codelineno-26-11></a>        <span class=n>max_turns</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>                            <span class=c1># conversation turn limit</span>
</span><span id=__span-26-12><a id=__codelineno-26-12 name=__codelineno-26-12 href=#__codelineno-26-12></a>    <span class=p>)</span>
</span><span id=__span-26-13><a id=__codelineno-26-13 name=__codelineno-26-13 href=#__codelineno-26-13></a>    <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span><span class=n>chat_model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s2>&quot;reviewer&quot;</span><span class=p>)</span>
</span><span id=__span-26-14><a id=__codelineno-26-14 name=__codelineno-26-14 href=#__codelineno-26-14></a>    <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>communicate</span><span class=p>(</span><span class=s2>&quot;Review src/auth.py for security issues&quot;</span><span class=p>)</span>
</span><span id=__span-26-15><a id=__codelineno-26-15 name=__codelineno-26-15 href=#__codelineno-26-15></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-26-16><a id=__codelineno-26-16 name=__codelineno-26-16 href=#__codelineno-26-16></a>
</span><span id=__span-26-17><a id=__codelineno-26-17 name=__codelineno-26-17 href=#__codelineno-26-17></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <p><strong>Claude Code request parameters:</strong></p> <table> <thead> <tr> <th>Parameter</th> <th>Type</th> <th>Default</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td><code>model</code></td> <td><code>str</code></td> <td><code>"sonnet"</code></td> <td><code>"sonnet"</code>, <code>"opus"</code>, or model ID</td> </tr> <tr> <td><code>system_prompt</code></td> <td><code>str</code></td> <td>None</td> <td>System instructions for the agent</td> </tr> <tr> <td><code>append_system_prompt</code></td> <td><code>str</code></td> <td>None</td> <td>Appended to existing system prompt</td> </tr> <tr> <td><code>permission_mode</code></td> <td><code>str</code></td> <td>None</td> <td><code>"default"</code>, <code>"acceptEdits"</code>, <code>"bypassPermissions"</code></td> </tr> <tr> <td><code>allowed_tools</code></td> <td><code>list[str]</code></td> <td>None</td> <td>Restrict to these tools only</td> </tr> <tr> <td><code>disallowed_tools</code></td> <td><code>list[str]</code></td> <td><code>[]</code></td> <td>Block specific tools</td> </tr> <tr> <td><code>max_turns</code></td> <td><code>int</code></td> <td>None</td> <td>Max conversation turns</td> </tr> <tr> <td><code>max_thinking_tokens</code></td> <td><code>int</code></td> <td>None</td> <td>Thinking budget</td> </tr> <tr> <td><code>continue_conversation</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Continue previous session</td> </tr> <tr> <td><code>resume</code></td> <td><code>str</code></td> <td>None</td> <td>Resume a specific session ID</td> </tr> <tr> <td><code>ws</code></td> <td><code>str</code></td> <td>None</td> <td>Subdirectory within repo</td> </tr> <tr> <td><code>add_dir</code></td> <td><code>str</code></td> <td>None</td> <td>Extra read-only directory mount</td> </tr> <tr> <td><code>mcp_tools</code></td> <td><code>list[str]</code></td> <td><code>[]</code></td> <td>MCP tool names to enable</td> </tr> <tr> <td><code>mcp_servers</code></td> <td><code>dict</code></td> <td><code>{}</code></td> <td>MCP server configurations</td> </tr> <tr> <td><code>mcp_config</code></td> <td><code>str\|Path</code></td> <td>None</td> <td>Path to MCP config file</td> </tr> <tr> <td><code>auto_finish</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Auto-append result extraction if agent doesn't finish</td> </tr> <tr> <td><code>verbose_output</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Show full agent output</td> </tr> <tr> <td><code>cli_include_summary</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Include cost/usage summary</td> </tr> </tbody> </table> <h3 id=gemini-cli>Gemini CLI<a class=headerlink href=#gemini-cli title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-27-1><a id=__codelineno-27-1 name=__codelineno-27-1 href=#__codelineno-27-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-27-2><a id=__codelineno-27-2 name=__codelineno-27-2 href=#__codelineno-27-2></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-27-3><a id=__codelineno-27-3 name=__codelineno-27-3 href=#__codelineno-27-3></a>
</span><span id=__span-27-4><a id=__codelineno-27-4 name=__codelineno-27-4 href=#__codelineno-27-4></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-27-5><a id=__codelineno-27-5 name=__codelineno-27-5 href=#__codelineno-27-5></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span>
</span><span id=__span-27-6><a id=__codelineno-27-6 name=__codelineno-27-6 href=#__codelineno-27-6></a>        <span class=n>provider</span><span class=o>=</span><span class=s2>&quot;gemini_code&quot;</span><span class=p>,</span>
</span><span id=__span-27-7><a id=__codelineno-27-7 name=__codelineno-27-7 href=#__codelineno-27-7></a>        <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gemini-2.5-pro&quot;</span><span class=p>,</span>
</span><span id=__span-27-8><a id=__codelineno-27-8 name=__codelineno-27-8 href=#__codelineno-27-8></a>        <span class=n>sandbox</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>                      <span class=c1># safety sandboxing (default)</span>
</span><span id=__span-27-9><a id=__codelineno-27-9 name=__codelineno-27-9 href=#__codelineno-27-9></a>        <span class=n>approval_mode</span><span class=o>=</span><span class=s2>&quot;auto_edit&quot;</span><span class=p>,</span>         <span class=c1># &quot;suggest&quot;, &quot;auto_edit&quot;, &quot;full_auto&quot;</span>
</span><span id=__span-27-10><a id=__codelineno-27-10 name=__codelineno-27-10 href=#__codelineno-27-10></a>    <span class=p>)</span>
</span><span id=__span-27-11><a id=__codelineno-27-11 name=__codelineno-27-11 href=#__codelineno-27-11></a>    <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span><span class=n>chat_model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s2>&quot;gemini_agent&quot;</span><span class=p>)</span>
</span><span id=__span-27-12><a id=__codelineno-27-12 name=__codelineno-27-12 href=#__codelineno-27-12></a>    <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>communicate</span><span class=p>(</span><span class=s2>&quot;Analyze the project structure&quot;</span><span class=p>)</span>
</span><span id=__span-27-13><a id=__codelineno-27-13 name=__codelineno-27-13 href=#__codelineno-27-13></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-27-14><a id=__codelineno-27-14 name=__codelineno-27-14 href=#__codelineno-27-14></a>
</span><span id=__span-27-15><a id=__codelineno-27-15 name=__codelineno-27-15 href=#__codelineno-27-15></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <p><strong>Gemini CLI request parameters:</strong></p> <table> <thead> <tr> <th>Parameter</th> <th>Type</th> <th>Default</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td><code>model</code></td> <td><code>str</code></td> <td><code>"gemini-2.5-pro"</code></td> <td>Gemini model name</td> </tr> <tr> <td><code>system_prompt</code></td> <td><code>str</code></td> <td>None</td> <td>System instructions</td> </tr> <tr> <td><code>sandbox</code></td> <td><code>bool</code></td> <td><code>True</code></td> <td>Enable sandbox protection</td> </tr> <tr> <td><code>yolo</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Auto-approve all actions (emits warning)</td> </tr> <tr> <td><code>approval_mode</code></td> <td><code>str</code></td> <td>None</td> <td><code>"suggest"</code>, <code>"auto_edit"</code>, <code>"full_auto"</code></td> </tr> <tr> <td><code>debug</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Debug mode</td> </tr> <tr> <td><code>include_directories</code></td> <td><code>list[str]</code></td> <td><code>[]</code></td> <td>Extra directories to include</td> </tr> <tr> <td><code>ws</code></td> <td><code>str</code></td> <td>None</td> <td>Subdirectory within repo</td> </tr> <tr> <td><code>verbose_output</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Show full agent output</td> </tr> <tr> <td><code>cli_include_summary</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Include cost/usage summary</td> </tr> </tbody> </table> <h3 id=codex-cli>Codex CLI<a class=headerlink href=#codex-cli title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-28-1><a id=__codelineno-28-1 name=__codelineno-28-1 href=#__codelineno-28-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-28-2><a id=__codelineno-28-2 name=__codelineno-28-2 href=#__codelineno-28-2></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-28-3><a id=__codelineno-28-3 name=__codelineno-28-3 href=#__codelineno-28-3></a>
</span><span id=__span-28-4><a id=__codelineno-28-4 name=__codelineno-28-4 href=#__codelineno-28-4></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-28-5><a id=__codelineno-28-5 name=__codelineno-28-5 href=#__codelineno-28-5></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span>
</span><span id=__span-28-6><a id=__codelineno-28-6 name=__codelineno-28-6 href=#__codelineno-28-6></a>        <span class=n>provider</span><span class=o>=</span><span class=s2>&quot;codex&quot;</span><span class=p>,</span>
</span><span id=__span-28-7><a id=__codelineno-28-7 name=__codelineno-28-7 href=#__codelineno-28-7></a>        <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-5.3-codex&quot;</span><span class=p>,</span>
</span><span id=__span-28-8><a id=__codelineno-28-8 name=__codelineno-28-8 href=#__codelineno-28-8></a>        <span class=n>sandbox</span><span class=o>=</span><span class=s2>&quot;workspace-write&quot;</span><span class=p>,</span>         <span class=c1># &quot;read-only&quot;, &quot;workspace-write&quot;, &quot;danger-full-access&quot;</span>
</span><span id=__span-28-9><a id=__codelineno-28-9 name=__codelineno-28-9 href=#__codelineno-28-9></a>        <span class=n>full_auto</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>                    <span class=c1># auto-approve with workspace-write sandbox</span>
</span><span id=__span-28-10><a id=__codelineno-28-10 name=__codelineno-28-10 href=#__codelineno-28-10></a>    <span class=p>)</span>
</span><span id=__span-28-11><a id=__codelineno-28-11 name=__codelineno-28-11 href=#__codelineno-28-11></a>    <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span><span class=n>chat_model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s2>&quot;codex_agent&quot;</span><span class=p>)</span>
</span><span id=__span-28-12><a id=__codelineno-28-12 name=__codelineno-28-12 href=#__codelineno-28-12></a>    <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>communicate</span><span class=p>(</span><span class=s2>&quot;Fix the failing tests in this project&quot;</span><span class=p>)</span>
</span><span id=__span-28-13><a id=__codelineno-28-13 name=__codelineno-28-13 href=#__codelineno-28-13></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-28-14><a id=__codelineno-28-14 name=__codelineno-28-14 href=#__codelineno-28-14></a>
</span><span id=__span-28-15><a id=__codelineno-28-15 name=__codelineno-28-15 href=#__codelineno-28-15></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <p><strong>Codex CLI request parameters:</strong></p> <table> <thead> <tr> <th>Parameter</th> <th>Type</th> <th>Default</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td><code>model</code></td> <td><code>str</code></td> <td><code>"gpt-5.3-codex"</code></td> <td>Codex model name</td> </tr> <tr> <td><code>system_prompt</code></td> <td><code>str</code></td> <td>None</td> <td>System instructions</td> </tr> <tr> <td><code>full_auto</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Auto-approve with workspace-write sandbox</td> </tr> <tr> <td><code>sandbox</code></td> <td><code>str</code></td> <td>None</td> <td><code>"read-only"</code>, <code>"workspace-write"</code>, <code>"danger-full-access"</code></td> </tr> <tr> <td><code>bypass_approvals</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Skip all approvals and sandbox</td> </tr> <tr> <td><code>skip_git_repo_check</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Don't require git repo</td> </tr> <tr> <td><code>output_schema</code></td> <td><code>str\|Path</code></td> <td>None</td> <td>JSON Schema file for structured output</td> </tr> <tr> <td><code>include_plan_tool</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Enable planning tool</td> </tr> <tr> <td><code>images</code></td> <td><code>list[str]</code></td> <td><code>[]</code></td> <td>Image attachments</td> </tr> <tr> <td><code>config_overrides</code></td> <td><code>dict</code></td> <td><code>{}</code></td> <td>Custom config key-value overrides</td> </tr> <tr> <td><code>ws</code></td> <td><code>str</code></td> <td>None</td> <td>Subdirectory within repo</td> </tr> <tr> <td><code>verbose_output</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Show full agent output</td> </tr> <tr> <td><code>cli_include_summary</code></td> <td><code>bool</code></td> <td><code>False</code></td> <td>Include cost/usage summary</td> </tr> </tbody> </table> <h3 id=context-and-session-management>Context and Session Management<a class=headerlink href=#context-and-session-management title="Permanent link">&para;</a></h3> <p>CLI providers have two layers of context:</p> <ul> <li><strong>Within a session</strong>: the CLI agent manages its own context via <code>--resume</code>. lionagi stores the <code>session_id</code> automatically and passes it on subsequent calls.</li> <li><strong>Across sessions</strong>: when a session grows too long, start a fresh CLI instance and use <code>progression=</code> to select which prior messages to inject as context. Branch's MessageManager is the durable record.</li> </ul> <div class="language-python highlight"><pre><span></span><code><span id=__span-29-1><a id=__codelineno-29-1 name=__codelineno-29-1 href=#__codelineno-29-1></a><span class=n>model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;claude_code&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;sonnet&quot;</span><span class=p>)</span>
</span><span id=__span-29-2><a id=__codelineno-29-2 name=__codelineno-29-2 href=#__codelineno-29-2></a>
</span><span id=__span-29-3><a id=__codelineno-29-3 name=__codelineno-29-3 href=#__codelineno-29-3></a><span class=c1># Normal: session resume is automatic</span>
</span><span id=__span-29-4><a id=__codelineno-29-4 name=__codelineno-29-4 href=#__codelineno-29-4></a><span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>communicate</span><span class=p>(</span><span class=s2>&quot;First task&quot;</span><span class=p>)</span>
</span><span id=__span-29-5><a id=__codelineno-29-5 name=__codelineno-29-5 href=#__codelineno-29-5></a><span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>communicate</span><span class=p>(</span><span class=s2>&quot;Follow-up&quot;</span><span class=p>)</span>  <span class=c1># resumes same session</span>
</span><span id=__span-29-6><a id=__codelineno-29-6 name=__codelineno-29-6 href=#__codelineno-29-6></a>
</span><span id=__span-29-7><a id=__codelineno-29-7 name=__codelineno-29-7 href=#__codelineno-29-7></a><span class=c1># Session too long -- rotate to fresh instance, carry context</span>
</span><span id=__span-29-8><a id=__codelineno-29-8 name=__codelineno-29-8 href=#__codelineno-29-8></a><span class=n>branch</span><span class=o>.</span><span class=n>chat_model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;claude_code&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;sonnet&quot;</span><span class=p>)</span>
</span><span id=__span-29-9><a id=__codelineno-29-9 name=__codelineno-29-9 href=#__codelineno-29-9></a><span class=n>recent</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>branch</span><span class=o>.</span><span class=n>msgs</span><span class=o>.</span><span class=n>progression</span><span class=p>)[</span><span class=o>-</span><span class=mi>30</span><span class=p>:]</span>
</span><span id=__span-29-10><a id=__codelineno-29-10 name=__codelineno-29-10 href=#__codelineno-29-10></a><span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>communicate</span><span class=p>(</span><span class=s2>&quot;Continue from here.&quot;</span><span class=p>,</span> <span class=n>progression</span><span class=o>=</span><span class=n>recent</span><span class=p>)</span>
</span></code></pre></div> <p>Session management:</p> <ol> <li>First call creates a new session. The CLI returns a <code>session_id</code>.</li> <li>lionagi stores the <code>session_id</code> on the endpoint.</li> <li>Subsequent calls pass <code>--resume</code> automatically.</li> <li>If the resumed session gets a new ID, lionagi updates automatically.</li> <li><code>iModel.copy()</code> creates a fresh session; <code>iModel.copy(share_session=True)</code> carries over the session ID.</li> </ol> <div class="language-python highlight"><pre><span></span><code><span id=__span-30-1><a id=__codelineno-30-1 name=__codelineno-30-1 href=#__codelineno-30-1></a><span class=c1># Fresh copy, independent session</span>
</span><span id=__span-30-2><a id=__codelineno-30-2 name=__codelineno-30-2 href=#__codelineno-30-2></a><span class=n>new_model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span><span id=__span-30-3><a id=__codelineno-30-3 name=__codelineno-30-3 href=#__codelineno-30-3></a>
</span><span id=__span-30-4><a id=__codelineno-30-4 name=__codelineno-30-4 href=#__codelineno-30-4></a><span class=c1># Copy that resumes the same CLI session</span>
</span><span id=__span-30-5><a id=__codelineno-30-5 name=__codelineno-30-5 href=#__codelineno-30-5></a><span class=n>resumed</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=n>share_session</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></code></pre></div> <h3 id=event-handlers>Event Handlers<a class=headerlink href=#event-handlers title="Permanent link">&para;</a></h3> <p>Set callbacks to observe the agent's streaming output:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-31-1><a id=__codelineno-31-1 name=__codelineno-31-1 href=#__codelineno-31-1></a><span class=n>model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;claude_code&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;sonnet&quot;</span><span class=p>)</span>
</span><span id=__span-31-2><a id=__codelineno-31-2 name=__codelineno-31-2 href=#__codelineno-31-2></a>
</span><span id=__span-31-3><a id=__codelineno-31-3 name=__codelineno-31-3 href=#__codelineno-31-3></a><span class=n>model</span><span class=o>.</span><span class=n>endpoint</span><span class=o>.</span><span class=n>update_handlers</span><span class=p>(</span>
</span><span id=__span-31-4><a id=__codelineno-31-4 name=__codelineno-31-4 href=#__codelineno-31-4></a>    <span class=n>on_text</span><span class=o>=</span><span class=k>lambda</span> <span class=n>chunk</span><span class=p>:</span> <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Text: </span><span class=si>{</span><span class=n>chunk</span><span class=o>.</span><span class=n>text</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>),</span>
</span><span id=__span-31-5><a id=__codelineno-31-5 name=__codelineno-31-5 href=#__codelineno-31-5></a>    <span class=n>on_tool_use</span><span class=o>=</span><span class=k>lambda</span> <span class=n>chunk</span><span class=p>:</span> <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Tool: </span><span class=si>{</span><span class=n>chunk</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>),</span>
</span><span id=__span-31-6><a id=__codelineno-31-6 name=__codelineno-31-6 href=#__codelineno-31-6></a>    <span class=n>on_thinking</span><span class=o>=</span><span class=k>lambda</span> <span class=n>chunk</span><span class=p>:</span> <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Thinking: </span><span class=si>{</span><span class=n>chunk</span><span class=o>.</span><span class=n>text</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>),</span>
</span><span id=__span-31-7><a id=__codelineno-31-7 name=__codelineno-31-7 href=#__codelineno-31-7></a>    <span class=n>on_final</span><span class=o>=</span><span class=k>lambda</span> <span class=n>session</span><span class=p>:</span> <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Done: </span><span class=si>{</span><span class=n>session</span><span class=o>.</span><span class=n>result</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>),</span>
</span><span id=__span-31-8><a id=__codelineno-31-8 name=__codelineno-31-8 href=#__codelineno-31-8></a><span class=p>)</span>
</span></code></pre></div> <table> <thead> <tr> <th>Provider</th> <th>Available Handlers</th> </tr> </thead> <tbody> <tr> <td><code>claude_code</code></td> <td><code>on_thinking</code>, <code>on_text</code>, <code>on_tool_use</code>, <code>on_tool_result</code>, <code>on_system</code>, <code>on_final</code></td> </tr> <tr> <td><code>gemini_code</code></td> <td><code>on_text</code>, <code>on_tool_use</code>, <code>on_tool_result</code>, <code>on_final</code></td> </tr> <tr> <td><code>codex</code></td> <td><code>on_text</code>, <code>on_tool_use</code>, <code>on_tool_result</code>, <code>on_final</code></td> </tr> </tbody> </table> <p>For more on multi-agent orchestration patterns with CLI providers, see <a href=../../for-ai-agents/claude-code-usage/ >CLI Agent Providers</a>.</p> <hr> <h2 id=provider-auto-detection>Provider Auto-Detection<a class=headerlink href=#provider-auto-detection title="Permanent link">&para;</a></h2> <p>If the <code>model</code> string contains a <code>/</code>, the prefix is treated as the provider name. This lets you skip the <code>provider=</code> parameter:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-32-1><a id=__codelineno-32-1 name=__codelineno-32-1 href=#__codelineno-32-1></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>iModel</span>
</span><span id=__span-32-2><a id=__codelineno-32-2 name=__codelineno-32-2 href=#__codelineno-32-2></a>
</span><span id=__span-32-3><a id=__codelineno-32-3 name=__codelineno-32-3 href=#__codelineno-32-3></a><span class=c1># These two are equivalent:</span>
</span><span id=__span-32-4><a id=__codelineno-32-4 name=__codelineno-32-4 href=#__codelineno-32-4></a><span class=n>m1</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;openai&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-4.1-mini&quot;</span><span class=p>)</span>
</span><span id=__span-32-5><a id=__codelineno-32-5 name=__codelineno-32-5 href=#__codelineno-32-5></a><span class=n>m2</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&quot;openai/gpt-4.1-mini&quot;</span><span class=p>)</span>
</span><span id=__span-32-6><a id=__codelineno-32-6 name=__codelineno-32-6 href=#__codelineno-32-6></a>
</span><span id=__span-32-7><a id=__codelineno-32-7 name=__codelineno-32-7 href=#__codelineno-32-7></a><span class=c1># Works with any provider</span>
</span><span id=__span-32-8><a id=__codelineno-32-8 name=__codelineno-32-8 href=#__codelineno-32-8></a><span class=n>m3</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&quot;anthropic/claude-sonnet-4-20250514&quot;</span><span class=p>)</span>
</span><span id=__span-32-9><a id=__codelineno-32-9 name=__codelineno-32-9 href=#__codelineno-32-9></a><span class=n>m4</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&quot;groq/llama-3.3-70b-versatile&quot;</span><span class=p>)</span>
</span><span id=__span-32-10><a id=__codelineno-32-10 name=__codelineno-32-10 href=#__codelineno-32-10></a><span class=n>m5</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&quot;gemini/gemini-2.5-flash&quot;</span><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=openai-compatible-custom-providers>OpenAI-Compatible Custom Providers<a class=headerlink href=#openai-compatible-custom-providers title="Permanent link">&para;</a></h2> <p>Any provider that implements the OpenAI chat completions API can be used with LionAGI. When <code>match_endpoint</code> does not recognize the provider name, it falls back to a generic OpenAI-compatible endpoint. Pass <code>base_url</code> to point at the custom server:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-33-1><a id=__codelineno-33-1 name=__codelineno-33-1 href=#__codelineno-33-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-33-2><a id=__codelineno-33-2 name=__codelineno-33-2 href=#__codelineno-33-2></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-33-3><a id=__codelineno-33-3 name=__codelineno-33-3 href=#__codelineno-33-3></a>
</span><span id=__span-33-4><a id=__codelineno-33-4 name=__codelineno-33-4 href=#__codelineno-33-4></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-33-5><a id=__codelineno-33-5 name=__codelineno-33-5 href=#__codelineno-33-5></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span>
</span><span id=__span-33-6><a id=__codelineno-33-6 name=__codelineno-33-6 href=#__codelineno-33-6></a>        <span class=n>provider</span><span class=o>=</span><span class=s2>&quot;together&quot;</span><span class=p>,</span>
</span><span id=__span-33-7><a id=__codelineno-33-7 name=__codelineno-33-7 href=#__codelineno-33-7></a>        <span class=n>model</span><span class=o>=</span><span class=s2>&quot;meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo&quot;</span><span class=p>,</span>
</span><span id=__span-33-8><a id=__codelineno-33-8 name=__codelineno-33-8 href=#__codelineno-33-8></a>        <span class=n>base_url</span><span class=o>=</span><span class=s2>&quot;https://api.together.xyz/v1&quot;</span><span class=p>,</span>
</span><span id=__span-33-9><a id=__codelineno-33-9 name=__codelineno-33-9 href=#__codelineno-33-9></a>        <span class=n>api_key</span><span class=o>=</span><span class=s2>&quot;your-together-key&quot;</span><span class=p>,</span>
</span><span id=__span-33-10><a id=__codelineno-33-10 name=__codelineno-33-10 href=#__codelineno-33-10></a>    <span class=p>)</span>
</span><span id=__span-33-11><a id=__codelineno-33-11 name=__codelineno-33-11 href=#__codelineno-33-11></a>    <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span><span class=n>chat_model</span><span class=o>=</span><span class=n>model</span><span class=p>)</span>
</span><span id=__span-33-12><a id=__codelineno-33-12 name=__codelineno-33-12 href=#__codelineno-33-12></a>    <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span><span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;Hello from a custom provider!&quot;</span><span class=p>)</span>
</span><span id=__span-33-13><a id=__codelineno-33-13 name=__codelineno-33-13 href=#__codelineno-33-13></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-33-14><a id=__codelineno-33-14 name=__codelineno-33-14 href=#__codelineno-33-14></a>
</span><span id=__span-33-15><a id=__codelineno-33-15 name=__codelineno-33-15 href=#__codelineno-33-15></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <p>The fallback endpoint uses <code>chat/completions</code>, bearer auth, and <code>application/json</code> content type.</p> <hr> <h2 id=async-context-manager>Async Context Manager<a class=headerlink href=#async-context-manager title="Permanent link">&para;</a></h2> <p>Both <code>iModel</code> and <code>Branch</code> support <code>async with</code> for resource cleanup:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-34-1><a id=__codelineno-34-1 name=__codelineno-34-1 href=#__codelineno-34-1></a><span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
</span><span id=__span-34-2><a id=__codelineno-34-2 name=__codelineno-34-2 href=#__codelineno-34-2></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-34-3><a id=__codelineno-34-3 name=__codelineno-34-3 href=#__codelineno-34-3></a>
</span><span id=__span-34-4><a id=__codelineno-34-4 name=__codelineno-34-4 href=#__codelineno-34-4></a><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-34-5><a id=__codelineno-34-5 name=__codelineno-34-5 href=#__codelineno-34-5></a>    <span class=c1># iModel context manager -- stops the rate-limited executor on exit</span>
</span><span id=__span-34-6><a id=__codelineno-34-6 name=__codelineno-34-6 href=#__codelineno-34-6></a>    <span class=k>async</span> <span class=k>with</span> <span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;openai&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-4.1-mini&quot;</span><span class=p>)</span> <span class=k>as</span> <span class=n>model</span><span class=p>:</span>
</span><span id=__span-34-7><a id=__codelineno-34-7 name=__codelineno-34-7 href=#__codelineno-34-7></a>        <span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span><span class=n>chat_model</span><span class=o>=</span><span class=n>model</span><span class=p>)</span>
</span><span id=__span-34-8><a id=__codelineno-34-8 name=__codelineno-34-8 href=#__codelineno-34-8></a>        <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span><span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;Hello!&quot;</span><span class=p>)</span>
</span><span id=__span-34-9><a id=__codelineno-34-9 name=__codelineno-34-9 href=#__codelineno-34-9></a>        <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-34-10><a id=__codelineno-34-10 name=__codelineno-34-10 href=#__codelineno-34-10></a>
</span><span id=__span-34-11><a id=__codelineno-34-11 name=__codelineno-34-11 href=#__codelineno-34-11></a>    <span class=c1># Branch context manager -- flushes logs on exit</span>
</span><span id=__span-34-12><a id=__codelineno-34-12 name=__codelineno-34-12 href=#__codelineno-34-12></a>    <span class=k>async</span> <span class=k>with</span> <span class=n>Branch</span><span class=p>(</span>
</span><span id=__span-34-13><a id=__codelineno-34-13 name=__codelineno-34-13 href=#__codelineno-34-13></a>        <span class=n>chat_model</span><span class=o>=</span><span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;openai&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-4.1-mini&quot;</span><span class=p>)</span>
</span><span id=__span-34-14><a id=__codelineno-34-14 name=__codelineno-34-14 href=#__codelineno-34-14></a>    <span class=p>)</span> <span class=k>as</span> <span class=n>branch</span><span class=p>:</span>
</span><span id=__span-34-15><a id=__codelineno-34-15 name=__codelineno-34-15 href=#__codelineno-34-15></a>        <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span><span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;Hello again!&quot;</span><span class=p>)</span>
</span><span id=__span-34-16><a id=__codelineno-34-16 name=__codelineno-34-16 href=#__codelineno-34-16></a>        <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span><span id=__span-34-17><a id=__codelineno-34-17 name=__codelineno-34-17 href=#__codelineno-34-17></a>
</span><span id=__span-34-18><a id=__codelineno-34-18 name=__codelineno-34-18 href=#__codelineno-34-18></a><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>())</span>
</span></code></pre></div> <hr> <h2 id=copying-models>Copying Models<a class=headerlink href=#copying-models title="Permanent link">&para;</a></h2> <p>Use <code>iModel.copy()</code> to create an independent instance with the same configuration but a fresh ID and executor. This is useful when you need separate rate-limiting or session state:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-35-1><a id=__codelineno-35-1 name=__codelineno-35-1 href=#__codelineno-35-1></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>iModel</span>
</span><span id=__span-35-2><a id=__codelineno-35-2 name=__codelineno-35-2 href=#__codelineno-35-2></a>
</span><span id=__span-35-3><a id=__codelineno-35-3 name=__codelineno-35-3 href=#__codelineno-35-3></a><span class=n>model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;openai&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-4.1-mini&quot;</span><span class=p>)</span>
</span><span id=__span-35-4><a id=__codelineno-35-4 name=__codelineno-35-4 href=#__codelineno-35-4></a>
</span><span id=__span-35-5><a id=__codelineno-35-5 name=__codelineno-35-5 href=#__codelineno-35-5></a><span class=c1># Fresh copy, no shared state</span>
</span><span id=__span-35-6><a id=__codelineno-35-6 name=__codelineno-35-6 href=#__codelineno-35-6></a><span class=n>model2</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span><span id=__span-35-7><a id=__codelineno-35-7 name=__codelineno-35-7 href=#__codelineno-35-7></a>
</span><span id=__span-35-8><a id=__codelineno-35-8 name=__codelineno-35-8 href=#__codelineno-35-8></a><span class=c1># For CLI providers: share_session=True carries over the session ID</span>
</span><span id=__span-35-9><a id=__codelineno-35-9 name=__codelineno-35-9 href=#__codelineno-35-9></a><span class=n>cli_model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;claude_code&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;sonnet&quot;</span><span class=p>)</span>
</span><span id=__span-35-10><a id=__codelineno-35-10 name=__codelineno-35-10 href=#__codelineno-35-10></a><span class=n>cli_model2</span> <span class=o>=</span> <span class=n>cli_model</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=n>share_session</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=rate-limiting-and-concurrency>Rate Limiting and Concurrency<a class=headerlink href=#rate-limiting-and-concurrency title="Permanent link">&para;</a></h2> <p><code>iModel</code> wraps a <code>RateLimitedAPIExecutor</code> that handles queuing and throttling. You can configure it at construction time:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-36-1><a id=__codelineno-36-1 name=__codelineno-36-1 href=#__codelineno-36-1></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>iModel</span>
</span><span id=__span-36-2><a id=__codelineno-36-2 name=__codelineno-36-2 href=#__codelineno-36-2></a>
</span><span id=__span-36-3><a id=__codelineno-36-3 name=__codelineno-36-3 href=#__codelineno-36-3></a><span class=n>model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span>
</span><span id=__span-36-4><a id=__codelineno-36-4 name=__codelineno-36-4 href=#__codelineno-36-4></a>    <span class=n>provider</span><span class=o>=</span><span class=s2>&quot;openai&quot;</span><span class=p>,</span>
</span><span id=__span-36-5><a id=__codelineno-36-5 name=__codelineno-36-5 href=#__codelineno-36-5></a>    <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-4.1-mini&quot;</span><span class=p>,</span>
</span><span id=__span-36-6><a id=__codelineno-36-6 name=__codelineno-36-6 href=#__codelineno-36-6></a>    <span class=n>queue_capacity</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>            <span class=c1># Max queued requests (default: 100, CLI: 10)</span>
</span><span id=__span-36-7><a id=__codelineno-36-7 name=__codelineno-36-7 href=#__codelineno-36-7></a>    <span class=n>capacity_refresh_time</span><span class=o>=</span><span class=mi>60</span><span class=p>,</span>      <span class=c1># Seconds between capacity refreshes</span>
</span><span id=__span-36-8><a id=__codelineno-36-8 name=__codelineno-36-8 href=#__codelineno-36-8></a>    <span class=n>limit_requests</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span>             <span class=c1># Max requests per cycle</span>
</span><span id=__span-36-9><a id=__codelineno-36-9 name=__codelineno-36-9 href=#__codelineno-36-9></a>    <span class=n>limit_tokens</span><span class=o>=</span><span class=mi>100_000</span><span class=p>,</span>          <span class=c1># Max tokens per cycle</span>
</span><span id=__span-36-10><a id=__codelineno-36-10 name=__codelineno-36-10 href=#__codelineno-36-10></a>    <span class=n>concurrency_limit</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>          <span class=c1># Max concurrent streaming requests</span>
</span><span id=__span-36-11><a id=__codelineno-36-11 name=__codelineno-36-11 href=#__codelineno-36-11></a><span class=p>)</span>
</span></code></pre></div> <p>CLI providers use lower defaults (<code>queue_capacity=10</code>, <code>concurrency_limit=3</code>) because each call spawns a subprocess.</p> <hr> <h2 id=multiple-models-in-one-branch>Multiple Models in One Branch<a class=headerlink href=#multiple-models-in-one-branch title="Permanent link">&para;</a></h2> <p>A <code>Branch</code> maintains a <code>chat_model</code> and a <code>parse_model</code>. By default <code>parse_model</code> mirrors <code>chat_model</code>, but you can set them independently:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-37-1><a id=__codelineno-37-1 name=__codelineno-37-1 href=#__codelineno-37-1></a><span class=kn>from</span><span class=w> </span><span class=nn>lionagi</span><span class=w> </span><span class=kn>import</span> <span class=n>Branch</span><span class=p>,</span> <span class=n>iModel</span>
</span><span id=__span-37-2><a id=__codelineno-37-2 name=__codelineno-37-2 href=#__codelineno-37-2></a>
</span><span id=__span-37-3><a id=__codelineno-37-3 name=__codelineno-37-3 href=#__codelineno-37-3></a><span class=n>branch</span> <span class=o>=</span> <span class=n>Branch</span><span class=p>(</span>
</span><span id=__span-37-4><a id=__codelineno-37-4 name=__codelineno-37-4 href=#__codelineno-37-4></a>    <span class=n>chat_model</span><span class=o>=</span><span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;openai&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-4.1-mini&quot;</span><span class=p>),</span>
</span><span id=__span-37-5><a id=__codelineno-37-5 name=__codelineno-37-5 href=#__codelineno-37-5></a>    <span class=n>parse_model</span><span class=o>=</span><span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;anthropic&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;claude-sonnet-4-20250514&quot;</span><span class=p>),</span>
</span><span id=__span-37-6><a id=__codelineno-37-6 name=__codelineno-37-6 href=#__codelineno-37-6></a><span class=p>)</span>
</span></code></pre></div> <p>You can also override the model per-call:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-38-1><a id=__codelineno-38-1 name=__codelineno-38-1 href=#__codelineno-38-1></a><span class=n>fast_model</span> <span class=o>=</span> <span class=n>iModel</span><span class=p>(</span><span class=n>provider</span><span class=o>=</span><span class=s2>&quot;groq&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;llama-3.3-70b-versatile&quot;</span><span class=p>)</span>
</span><span id=__span-38-2><a id=__codelineno-38-2 name=__codelineno-38-2 href=#__codelineno-38-2></a>
</span><span id=__span-38-3><a id=__codelineno-38-3 name=__codelineno-38-3 href=#__codelineno-38-3></a><span class=c1># Use the fast model just for this one call</span>
</span><span id=__span-38-4><a id=__codelineno-38-4 name=__codelineno-38-4 href=#__codelineno-38-4></a><span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>branch</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span>
</span><span id=__span-38-5><a id=__codelineno-38-5 name=__codelineno-38-5 href=#__codelineno-38-5></a>    <span class=n>instruction</span><span class=o>=</span><span class=s2>&quot;Quick question.&quot;</span><span class=p>,</span>
</span><span id=__span-38-6><a id=__codelineno-38-6 name=__codelineno-38-6 href=#__codelineno-38-6></a>    <span class=n>imodel</span><span class=o>=</span><span class=n>fast_model</span><span class=p>,</span>
</span><span id=__span-38-7><a id=__codelineno-38-7 name=__codelineno-38-7 href=#__codelineno-38-7></a><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=environment-variable-reference>Environment Variable Reference<a class=headerlink href=#environment-variable-reference title="Permanent link">&para;</a></h2> <table> <thead> <tr> <th>Variable</th> <th>Provider</th> </tr> </thead> <tbody> <tr> <td><code>OPENAI_API_KEY</code></td> <td>OpenAI</td> </tr> <tr> <td><code>ANTHROPIC_API_KEY</code></td> <td>Anthropic</td> </tr> <tr> <td><code>GEMINI_API_KEY</code></td> <td>Google Gemini</td> </tr> <tr> <td><code>GROQ_API_KEY</code></td> <td>Groq</td> </tr> <tr> <td><code>OPENROUTER_API_KEY</code></td> <td>OpenRouter</td> </tr> <tr> <td><code>PERPLEXITY_API_KEY</code></td> <td>Perplexity</td> </tr> <tr> <td><code>NVIDIA_NIM_API_KEY</code></td> <td>NVIDIA NIM</td> </tr> <tr> <td><code>EXA_API_KEY</code></td> <td>Exa</td> </tr> <tr> <td><code>LIONAGI_CHAT_PROVIDER</code></td> <td>Default provider (default: <code>openai</code>)</td> </tr> <tr> <td><code>LIONAGI_CHAT_MODEL</code></td> <td>Default model (default: <code>gpt-4.1-mini</code>)</td> </tr> </tbody> </table> <p>These can be set as environment variables or placed in <code>.env</code>, <code>.env.local</code>, or <code>.secrets.env</code> files in your project root.</p> <hr> <h2 id=troubleshooting>Troubleshooting<a class=headerlink href=#troubleshooting title="Permanent link">&para;</a></h2> <p><strong>"Provider must be provided"</strong> -- You passed a <code>model</code> string without a <code>/</code> separator and did not set <code>provider=</code>. Either use slash syntax (<code>model="openai/gpt-4.1-mini"</code>) or pass <code>provider=</code> explicitly.</p> <p><strong>"API key is required for authentication"</strong> -- The environment variable for your provider is not set. Check the table above for the correct variable name.</p> <p><strong>"ollama is not installed"</strong> -- Install the Ollama extra: <code>uv pip install "lionagi[ollama]"</code>.</p> <p><strong>Slow CLI providers</strong> -- CLI providers spawn subprocesses. If calls seem slow, that is expected. Avoid high concurrency with CLI providers.</p> <p><strong>Rate limit errors (429)</strong> -- LionAGI retries with exponential backoff automatically. If you still hit limits, reduce <code>limit_requests</code> or <code>limit_tokens</code> in the <code>iModel</code> constructor.</p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_datetime" title="February 13, 2026 03:47:24 UTC">2026-02-13 03:47:24</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_datetime" title="August 26, 2025 12:17:31 UTC">2025-08-26 12:17:31</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../ class="md-footer__link md-footer__link--prev" aria-label="Previous: Integrations"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Integrations </div> </div> </a> <a href=../vector-stores/ class="md-footer__link md-footer__link--next" aria-label="Next: Vector Stores"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Vector Stores </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024-2026 Ocean Li and LionAGI Contributors </div> </div> <div class=md-social> <a href=https://github.com/khive-ai/lionagi target=_blank rel=noopener title=GitHub class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://discord.gg/lionagi target=_blank rel=noopener title="Discord Community" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M492.5 69.8c-.2-.3-.4-.6-.8-.7-38.1-17.5-78.4-30-119.7-37.1-.4-.1-.8 0-1.1.1s-.6.4-.8.8c-5.5 9.9-10.5 20.2-14.9 30.6-44.6-6.8-89.9-6.8-134.4 0-4.5-10.5-9.5-20.7-15.1-30.6-.2-.3-.5-.6-.8-.8s-.7-.2-1.1-.2C162.5 39 122.2 51.5 84.1 69c-.3.1-.6.4-.8.7C7.1 183.5-13.8 294.6-3.6 404.2c0 .3.1.5.2.8s.3.4.5.6c44.4 32.9 94 58 146.8 74.2.4.1.8.1 1.1 0s.7-.4.9-.7c11.3-15.4 21.4-31.8 30-48.8.1-.2.2-.5.2-.8s0-.5-.1-.8-.2-.5-.4-.6-.4-.3-.7-.4c-15.8-6.1-31.2-13.4-45.9-21.9-.3-.2-.5-.4-.7-.6s-.3-.6-.3-.9 0-.6.2-.9.3-.5.6-.7c3.1-2.3 6.2-4.7 9.1-7.1.3-.2.6-.4.9-.4s.7 0 1 .1c96.2 43.9 200.4 43.9 295.5 0 .3-.1.7-.2 1-.2s.7.2.9.4c2.9 2.4 6 4.9 9.1 7.2.2.2.4.4.6.7s.2.6.2.9-.1.6-.3.9-.4.5-.6.6c-14.7 8.6-30 15.9-45.9 21.8-.2.1-.5.2-.7.4s-.3.4-.4.7-.1.5-.1.8.1.5.2.8c8.8 17 18.8 33.3 30 48.8.2.3.6.6.9.7s.8.1 1.1 0c52.9-16.2 102.6-41.3 147.1-74.2.2-.2.4-.4.5-.6s.2-.5.2-.8c12.3-126.8-20.5-236.9-86.9-334.5zm-302 267.7c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.4 59.2-52.8 59.2m195.4 0c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.2 59.2-52.8 59.2"/></svg> </a> <a href=https://twitter.com/lionagi target=_blank rel=noopener title=Twitter class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg> </a> <a href=https://www.linkedin.com/in/quantoceanli/ target=_blank rel=noopener title=LinkedIn class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <div class=md-consent data-md-component=consent id=__consent hidden> <div class=md-consent__overlay></div> <aside class=md-consent__inner> <form class="md-consent__form md-grid md-typeset" name=consent> <h4>Cookie consent</h4> <p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p> <input class=md-toggle type=checkbox id=__settings> <div class=md-consent__settings> <ul class=task-list> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=analytics checked> <span class=task-list-indicator></span> Google Analytics </label> </li> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=github checked> <span class=task-list-indicator></span> GitHub </label> </li> </ul> </div> <div class=md-consent__controls> <button class="md-button md-button--primary">Accept</button> <button type=reset class="md-button md-button--primary">Reject</button> <label class=md-button for=__settings>Manage settings</label> </div> </form> </aside> </div> <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script> <script id=__config type=application/json>{"base": "../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.path", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "stable", "provider": "mike"}}</script> <script src=../../assets/javascripts/bundle.f55a23d4.min.js></script> <script src=https://unpkg.com/mermaid@10/dist/mermaid.min.js></script> <script src=../../javascripts/mermaid-config.js></script> <script src=../../javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>
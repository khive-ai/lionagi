{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lionagi.tools.types import chunk\n",
        "\n",
        "url = \"https://arxiv.org/pdf/2501.18438\"\n",
        "title = \"O3-MINI VS DEEPSEEK-R1: WHICH ONE IS SAFER?\"\n",
        "date = \"2025-01-31\"\n",
        "author = \"Aitor Arrieta\"\n",
        "\n",
        "chunks = chunk(\n",
        "    url,\n",
        "    reader_tool=\"docling\",\n",
        "    metadata={\n",
        "        \"url\": url,\n",
        "        \"title\": title,\n",
        "        \"date\": date,\n",
        "        \"author\": author,\n",
        "    },\n",
        "    chunk_size=2000,\n",
        "    overlap=0.05,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(chunks);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## O3-MINI VS DEEPSEEK-R1: WHICH ONE IS SAFER?\n",
            "\n",
            "Aitor Arrieta Mondragon University Mondragon, Spain aarrieta@mondragon.edu\n",
            "\n",
            "Miriam Ugarte Mondragon University Mondragon, Spain mugarte@mondragon.edu\n",
            "\n",
            "Pablo Valle\n",
            "\n",
            "Mondragon University Mondragon, Spain pvalle@mondragon.edu\n",
            "\n",
            "Sergio Segura University of Seville Seville, Spain sergiosegura@us.es\n",
            "\n",
            "## ABSTRACT\n",
            "\n",
            "The irruption of DeepSeek-R1 constitutes a turning point for the AI industry in general and the LLMs in particular. Its capabilities have demonstrated outstanding performance in several tasks, including creative thinking, code generation, maths and automated program repair, at apparently lower execution cost. However, LLMs must adhere to an important qualitative property, i.e., their alignment with safety and human values. A clear competitor of DeepSeek-R1 is its American counterpart, OpenAI's o3-mini model, which is expected to set high standards in terms of performance, safety and cost. In this paper we conduct a systematic assessment of the safety level of both, DeepSeek-R1 (70b version) and OpenAI's o3-mini (beta version). 1 To this end, we make use of our recently released automated safety testing tool, named ASTRAL. By leveraging this tool, we automatically and systematically generate and execute a total of 1260 unsafe test inputs on both models. After conducting a semi-automated assessment of the outcomes provided by both LLMs, the results indicate that DeepSeek-R1 is highly unsafe as compared to OpenAI's o3-mini. Based on our evaluation, DeepSeek-R1 answered unsafely to 11.98% of the executed prompts whereas o3-mini only to 1.19%.\n",
            "\n",
            "Warning: This report contains extracts from unsafe test inputs generated by ASTRAL and outputs provided by the tested models, which may upset some readers. Reader discretion is advised.\n",
            "\n",
            "## 1 Introduction\n",
            "\n",
            "DeepSeek-R1 [1] seems to have revolutionized the AI industry by providing an LLM that, apparently, competes with the latest State-of-the-Art private LLMs from OpenAI at lower inference cost. On the other hand, OpenAI has set hig\n"
          ]
        }
      ],
      "source": [
        "print(chunks[0].content);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "chunks = chunk(\n",
        "  url,\n",
        "  reader_tool = \"docling\",\n",
        "  chunk_by = \"tokens\",\n",
        "  metadata = {\n",
        "    \"url\": url,\n",
        "    \"title\": title,\n",
        "    \"date\": date,\n",
        "    \"author\": author,\n",
        "  },\n",
        "  chunk_size = 300,\n",
        "  overlap = 0.05,\n",
        ");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(chunks);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## O3-MINI VS DEEPSEEK-R1: WHICH ONE IS SAFER? Aitor Arrieta Mondragon University Mondragon, Spain aarrieta@mondragon.edu Miriam Ugarte Mondragon University Mondragon, Spain mugarte@mondragon.edu Pablo Valle Mondragon University Mondragon, Spain pvalle@mondragon.edu Sergio Segura University of Seville Seville, Spain sergiosegura@us.es ## ABSTRACT The irruption of DeepSeek-R1 constitutes a turning point for the AI industry in general and the LLMs in particular. Its capabilities have demonstrated outstanding performance in several tasks, including creative thinking, code generation, maths and automated program repair, at apparently lower execution cost. However, LLMs must adhere to an important qualitative property, i.e., their alignment with safety and human values. A clear competitor of DeepSeek-R1 is its American counterpart, OpenAI's o3-mini model, which is expected to set high standards in terms of performance, safety and cost. In this paper we conduct a systematic assessment of the safety level of both, DeepSeek-R1 (70b version) and OpenAI's o3-mini (beta version). 1 To this end, we make use of our recently released automated safety testing tool, named ASTRAL. By leveraging this tool, we automatically and systematically generate and execute a total of 1260 unsafe test inputs on both models. After conducting a semi-automated assessment of the outcomes provided by both LLMs, the results indicate that DeepSeek-R1 is highly unsafe as compared to OpenAI's o3-mini. Based on our evaluation, DeepSeek-R1 answered unsafely to 11.98% of the executed prompts whereas o3-mini only to 1.19%. Warning: This report contains extracts from unsafe test inputs generated by ASTRAL and outputs provided by the tested models, which may upset some readers. Reader discretion is advised. ## 1 Introduction DeepSeek-R1 [1] seems to have revolutionized the AI industry by providing an LLM that, apparently, competes with the latest State-of-the-Art private LLMs from OpenAI at lower inference cost. On the other hand, OpenAI has set high the bar for their o3-mini model, which is expected too to provide\n"
          ]
        }
      ],
      "source": [
        "print(chunks[0].content);"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
